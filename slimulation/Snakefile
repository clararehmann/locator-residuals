import numpy as np
import os, sys, subprocess, glob, json
from pathlib import Path

rng = np.random.default_rng(seed=666)

if os.path.exists('logs'):
    pass
else:
    os.makedirs('logs/')
output_dir = 'out/'

jsons = os.path.join(output_dir, 'jsons/')
treeouts = os.path.join(output_dir, 'trees/')
gtouts = os.path.join(output_dir, 'genotypes/')
tsouts = os.path.join(output_dir, 'training_sets/')
metaouts = os.path.join(output_dir, 'metadata/')
locouts = os.path.join(output_dir, 'predlocs/')


"""
# wildcards
sigmas = [0.5, 0.75, 1.25, 2.0]
mus = [0.0, 0.5, 1.0, 1.5]
sim_replicates = np.arange(100)
skews = [0.5, 0.6, 0.7, 0.8, 0.9]
sampling = ['half','point']
ts_replicates = np.arange(1)
"""

#2_sigma_1.25_mu_0.5
sigmas=[1.25]
mus = [0.5]
sim_replicates=[2]
skews = [0.9]
sampling = ['point', 'half']
ts_replicates=[0]

# slimulation patterns
slimout_pattern = "{sim_rep}_sigma_{sigma}_mu_{mu}"
slimout_base = expand(slimout_pattern, sim_rep=sim_replicates, sigma=sigmas, mu=mus)
seeds = rng.integers(0, int(1e10), len(slimout_base))
slimout_base = [slimout_base[i] + '_' + str(seeds[i]) for i in range(len(slimout_base))]

# genotype and metadata patterns
gt_pattern = gtouts + "{sim_rep}_sigma_{sigma}_mu_{mu}_{n}.vcf"
meta_pattern = metaouts + "{sim_rep}_sigma_{sigma}_mu_{mu}_{n}.txt"

# training set patterns
uniform_locpattern = "{sim_rep}_sigma_{sigma}_mu_{mu}_uniform_{n}"
uniform_locbase = expand(uniform_locpattern, sim_rep=sim_replicates, sigma=sigmas, mu=mus, n=ts_replicates)
skewed_locpattern = "{sim_rep}_sigma_{sigma}_mu_{mu}_{samp}_{skew}_{n}"
skewed_locbase = expand(skewed_locpattern, sim_rep=sim_replicates, sigma=sigmas, mu=mus, samp=sampling, skew=skews, n=ts_replicates)


localrules: generate_json, all

rule all:
    input: [locouts + i + '_predlocs.txt' for i in uniform_locbase] + [locouts + i + '_predlocs.txt' for i in skewed_locbase]
    #input: [treeouts + slimout_base[i] + '.trees' for i in range(len(slimout_base))]



rule generate_json:
    params:
        sigma='{sigma}',
        mu='{mu}'#,
#        seed=lambda wildcards: '{seed}'
    output: jsons + slimout_pattern + '.json'#+ '_{seed}.json'
    run:
        info = {
                'SI':float(params.sigma),
                'SM':float(params.sigma),
                'SD':float(params.sigma),
                'BIAS':float(params.mu)} #'SEED':int(params.seed),
        with open(str(output), 'w') as outfile:
            json.dump(info, outfile)

rule slimulate:
    input: jsons + slimout_pattern + '.json'
    params:
        outdir = treeouts + slimout_pattern
#        seed = '{seed}'
    output: treeouts + slimout_pattern + '.trees'
    conda: 'SLiM'
    resources: 
        time='48:00:00'
    shell:
        '''
        slim -d 'ParamFile="{input}"' -d 'OUTDIR="{params.outdir}"' ../scripts/biased_migration.slim
        '''

rule process_ts:
    input: treeouts + slimout_pattern + '.trees'
    output: [(tsouts + uniform_locpattern + '.txt').replace('{n}', str(n)) for n in np.arange(1)] + #uniform ts
            [(tsouts + skewed_locpattern + '.txt').replace('{n}', str(n)).replace('{samp}', sampling[0]).replace('{skew}', str(s)) for n in np.arange(1) for s in skews] +
            [(tsouts + skewed_locpattern + '.txt').replace('{n}', str(n)).replace('{samp}', sampling[1]).replace('{skew}', str(s)) for n in np.arange(1) for s in skews] +
            [gt_pattern.replace('{n}', str(n)) for n in np.arange(1)]

    conda: 'pyslim'
    resources:
        time='1:00:00'
    shell: 'python ../scripts/sample_treeseq.py {input}'

rule ts_to_zarr:
    input: [gt_pattern.replace('{n}', str(n)) for n in np.arange(1)]
    output: [directory(gt_pattern.replace('{n}', str(n)).replace('.vcf','.zarr')) for n in np.arange(1)]
    conda: 'pyslim'
    resources:
        mem_mb=30000
    shell: 
        """
        python ../../locator/scripts/vcf_to_zarr.py --vcf {input} --zarr {output}
        rm {input}
        """
rule locate_uniform:
    input: 
        trainingset = tsouts + uniform_locpattern + '.txt',
        genotype = gt_pattern.replace('vcf','zarr')
    params: locouts + uniform_locpattern
    output: locouts + uniform_locpattern + '_predlocs.txt'
    conda: 'py39'
    resources:
        time='2:00:00',
        partition='kerngpu',
        mem_mb=30000
    shell: 'python ../../locator/scripts/locator.py --zarr {input.genotype} --sample_data {input.trainingset} --max_SNPs 100000 --out {params} --keep_weights'

rule locate_skew:
    input: 
        trainingset = tsouts + skewed_locpattern + '.txt',
        genotype = gt_pattern.replace('vcf','zarr')
    params: locouts + skewed_locpattern
    output: locouts + skewed_locpattern + '_predlocs.txt'
    conda: 'py39'
    resources:
        time='2:00:00',
        partition='kerngpu',
        mem_mb=30000
    shell: 'python ../../locator/scripts/locator.py --zarr {input.genotype} --sample_data {input.trainingset} --max_SNPs 100000 --out {params} --keep_weights'




